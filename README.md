![header](https://capsule-render.vercel.app/api?type=transparent&color=white&height=200&section=header&text=HUMANE_LAB&animation=blink&fontSize=50&fontColor=d6ace6)

# 대규모 언어 모델의 소수 검증 능력 심층 평가: ChatGPT와 PaLM 2를 중심으로
이 저장소는 "대규모 언어 모델의 소수 검증 능력 심층 평가: ChatGPT와 PaLM 2를 중심으로"라는 제목의 논문에 사용된 데이터셋과 코드를 포함하고 있습니다.
## 연구 목표

이 연구는 ChatGPT와 PaLM 2 언어 모델의 소수 검증 추론 능력을 심층적으로 평가하는 것을 목표로 합니다. 구체적으로, 같은 숫자에 대해 소수인지 합성수인지 질문하여 두 질문 모두 맞춘 경우에만 해당 언어 모델이 성공적으로 소수 검증을 수행한 것으로 간주합니다. 또한 합성수를 검증 대상에 포함시켜 응답 편향을 고려한 포괄적인 조사를 수행합니다.

## 데이터셋
소수 664개와 합성수 1458개로 구성된 데이터셋을 사용합니다. 소수는 자릿수에 따라, 합성수는 가장 작은 약수의 크기와 자릿수에 따라 난이도를 구분합니다.

## 연구 결과
난도 증가에 따라 소수 대상 검증 정확도가 감소함
연산 오류율을 반영한 경우, 난도 증가에 따라 합성수 대상 검증 정확도가 감소함
난도 증가에 따라 연산 오류율이 증가하는 경향성 발견
ChatGPT가 PaLM 2보다 전반적으로 높은 소수 검증 성능을 보였습니다. 단순한 질문에 기반한 성능 벤치마크는 언어 모델 능력을 잘못 평가할 수 있으며, 특정 능력을 다각도로 평가하는 심층 분석이 필요함을 시사합니다.

## 기여 및 피드백
이 프로젝트에 대한 기여와 피드백을 환영합니다. 연구 내용이나 코드에 대한 제안이 있다면 이슈를 생성하거나 Pull Request를 보내주시기 바랍니다.
