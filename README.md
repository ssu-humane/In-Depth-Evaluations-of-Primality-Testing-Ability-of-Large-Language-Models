![header](https://capsule-render.vercel.app/api?type=transparent&color=white&height=200&section=header&text=HUMANE_LAB&animation=blink&fontSize=50&fontColor=d6ace6)



# GPT-reasoning-prompting
:octocat: Repository for data and code that tests the reasoning ability of the GPT model.

## I USED
<img src="https://img.shields.io/badge/python-3776AB?style=flat-square&logo=Python&logoColor=white"/> 

## It is started by
How Language Model Hallucinations Can Snowball : https://arxiv.org/abs/2305.13534

In my opinion, I thought that the dataset in this paper would be biased because it is a dataset with only yes or no.

## Dataset

asdf

## Expriment

asdf 

## Result

|제목|내용|설명|
|------|---|---|
|테스트1|테스트2|테스트3|
|테스트1|테스트2|테스트3|
|테스트1|테스트2|테스트3|
